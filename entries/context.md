## Context

The context of an LLM is the list of tokens that are provided to the LLM in order to generate the next token in a respons. In case of a chat-bot, this is usually the entire conversation so far up to the maximum context size. The maximum context size thus determines how much information the LLM can still take into account when generating the next response. (This is why chat-bots seem to 'lose the thread' of the conversation after a while.)

